{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 7 - Matrix Inverse, Iterative Methods 👾\n",
        "\n",
        "**Learning Objectives**\n",
        "* Compute the matrix inverse using LU Decomposition.\n",
        "* Interpret the inverse matrix to determine the system's response to external forcings\n",
        "* Check the stability of our system by computing the condition number and determining the number of suspect digits.\n",
        "* Check if a matrix is diagonally dominant and implement the Gauss-Seidel methods for solving a system of linear equations."
      ],
      "metadata": {
        "id": "taoVXEMVbxdY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating/Interpreting Inverse Coefficients\n",
        "\n",
        "**C&C Case Study 12.1: System of 5 Reactors with Unknown Concentrations**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/cdefinnda/ECI-115_HW-Images/blob/main/cha32077_1203.png?raw=true\" alt=\"cha32077_1203\" width=500>\n",
        "</p>\n",
        "\n",
        ">* Reactor 1: $Q_{01}c_1+Q_{31}c_3=Q_{12}c_1+Q_{15}c_1 \\rightarrow 6c_1-c_3=50$\n",
        "* Reactor 2: $Q_{12}c_1=Q_{25}c_2+Q_{24}c_2+Q_{23}c_2 \\rightarrow -3c_1+3c_2=0$\n",
        "* Reactor 3: $-c_2+9c_3=160$\n",
        "* Reactor 4: $-c_2-8c_3+11c_4-2c_5=0$\n",
        "* Reactor 5: $-3c_1-c_2+4c_5=0$"
      ],
      "metadata": {
        "id": "F82Q1FTFlizC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up Linear System (Same as L06 Coding Notebook)"
      ],
      "metadata": {
        "id": "IhODghAnnBjD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nDqVC1wwS94"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import scipy.linalg as sl\n",
        "\n",
        "# Set Up Lineary System\n",
        "A = np.array([[6, 0, -1, 0, 0],\n",
        "              [-3, 3, 0, 0, 0],\n",
        "              [0, -1, 9, 0, 0],\n",
        "              [0, -1, -8, 11, -2],\n",
        "              [-3, -1, 0, 0, 4]])\n",
        "\n",
        "b = np.array([50, 0, 160, 0, 0]).T  # Numpy will assume the dimensions of a 1D\n",
        "                                    # array so that matrix math works out.\n",
        "\n",
        "n = A.shape[0]                      # Store # of rows of A for LU Decomposition\n",
        "\n",
        "# Convert all elements of A and b to float\n",
        "A = A.astype(float)\n",
        "b = b.astype(float)\n",
        "\n",
        "# Check if Matrix A is singular (i.e., det = 0)\n",
        "#print(sl.det(A))   # We know from last time that A is not singular"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform LU Decomposition"
      ],
      "metadata": {
        "id": "wzMtYd5um_BT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEQxU2bJwS95"
      },
      "outputs": [],
      "source": [
        "# LU Decomposition\n",
        "# Note: This does not include partial pivoting and may encounter divide by zero errors\n",
        "# See C&C Figure 10.2 for pseudocode for LU with partial pivoting\n",
        "L = np.eye(n)\n",
        "U = A.copy()\n",
        "\n",
        "for k in range(n-1):\n",
        "    for i in range(k+1,n):\n",
        "        L[i,k] = U[i,k] / U[k,k] # Multiplication Factor\n",
        "        U[i,:] = U[i,:] - L[i,k] * U[k,:] # Modify row i based on pivot row k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFfuoWyuwS95"
      },
      "source": [
        "### Solve for Matrix Inverse using LU Decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By definition, $A$ and $A^{-1}$ have the following relationship:\n",
        "$$\n",
        "AA^{-1}=I=\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 0 & 0 & 0\\\\\n",
        "0 & 1 & 0 & 0 & 0\\\\\n",
        "0 & 0 & 1 & 0 & 0\\\\\n",
        "0 & 0 & 0 & 1 & 0\\\\\n",
        "0 & 0 & 0 & 0 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "To solve for $A^{-1}$, we can break the matrix up into the following column vectors:\n",
        "\n",
        "$$A^{-1}=[x_1\\   x_2\\   x_3\\   x_4\\   x_5]$$\n",
        "\n",
        "Where:\n",
        ">$$\n",
        "Ax_1=\n",
        "\\begin{bmatrix}\n",
        "1\\\\\n",
        "0\\\\\n",
        "0\\\\\n",
        "0\\\\\n",
        "0\n",
        "\\end{bmatrix}\n",
        "$$\n",
        ">\n",
        ">$$\n",
        "Ax_2=\n",
        "\\begin{bmatrix}\n",
        "0\\\\\n",
        "1\\\\\n",
        "0\\\\\n",
        "0\\\\\n",
        "0\n",
        "\\end{bmatrix}\n",
        "$$\n",
        ">\n",
        ">and so on...\n",
        "\n",
        "By breaking up $A^{-1}$ into individual column vectors ($x_1, x_2, x_3, x_4, x_5$), we can use the LU Decomposition of $A$ to solve for $x_1$, $x_2$, $x_3$, $x_4$ and $x_5$ individually, by first solving for $d_1$ by forward substitution:\n",
        "\n",
        "$$\n",
        "L d_1 = Ax_1\n",
        "$$\n",
        "\n",
        "And then solving for $x_1$ by back substitution:\n",
        "\n",
        "$$\n",
        "U x_1 = d_1\n",
        "$$\n",
        "\n",
        "This process can then be repeated for the all other columns to obtain $x_2, x_3, x_4,$ and $x_5$."
      ],
      "metadata": {
        "id": "Yzbr71vso62u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this process requires repeated forward/back substitution, it helps to define a function that does this for us automatically:"
      ],
      "metadata": {
        "id": "PaCvoEilp9vg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyxhzSv4wS95"
      },
      "outputs": [],
      "source": [
        "# Inputs: L, U, b\n",
        "# Outputs: x such that LUx = b\n",
        "def forward_back_sub(L, U, b):\n",
        "\n",
        "    # forward substitution\n",
        "    d = np.zeros(n)\n",
        "    d[0] = b[0] / L[0,0]\n",
        "\n",
        "    for i in range(1,n):\n",
        "        d[i] = (b[i] - L[i,:] @ d) / L[i,i]\n",
        "\n",
        "    # back substitution\n",
        "    x = np.zeros(n)\n",
        "    x[-1] = d[-1] / U[-1,-1] # index -1 for last element\n",
        "\n",
        "    for i in range(n-2,-1,-1): # loop backward starting from second-to-last row\n",
        "        x[i] = (d[i] - U[i,i+1:n] @ x[i+1:n]) / U[i,i]\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64TIeNGLwS95"
      },
      "source": [
        "With this function defined, we can compute $\\mathbf{A^{-1}}$ using the function iterate through the columns of an identity matrix $\\mathbf{I_j}$ in order to comput the corresponding columns of $\\mathbf{A^{-1}_j}$.\n",
        "\n",
        "Note: The original $\\mathbf{b}$ vector is not used here. The inverse only depends on $\\mathbf{A}$."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "💪 Complete the code below:"
      ],
      "metadata": {
        "id": "BLpbXbgk8AsA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVzauE4lwS95"
      },
      "outputs": [],
      "source": [
        "# Solve for inverse using RHS columns from I\n",
        "I = np.eye(n)\n",
        "Ainv = np.zeros((n,n))\n",
        "\n",
        "for j in range(n):\n",
        "    # [Fill in code here to solve for the columns of Ainv using foward_back_sub().]\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "print(Ainv)\n",
        "\n",
        "\n",
        "print('\\n Compare to SciPy function (sl.inv(A)):', np.allclose(Ainv, sl.inv(A)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpreting the Matrix Inverse ($\\mathbf{A^{-1}}$)"
      ],
      "metadata": {
        "id": "ziXHzSizcaZL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_ILscIPwS95"
      },
      "source": [
        "The coefficients from the inverse help us interpret the relationship between the forcing and the unknown system states. Last time we changed the input forcing $c_{01}=10$ to $c_{01}=20$ and solved again to find the unknown states. Here we can see that inverse coefficients $a_{ij}^{-1}$ represent the change in state variable $i$ per unit change in forcing $j$.\n",
        "\n",
        "This change in $c_{01}$ causes the first forcing element, $b_1 = Q_{01}c_{01}$, to change 50 units (note $Q_{01}=5$ is unchanged). So, we would expect the unknown $c_2$ to change by $0.17 (50) = 8.5$ units. The change in $c_3$ would be $0.019 (50) = 0.95$ units.\n",
        "\n",
        "This interpretation depends on the order of the equations in the original matrix, which is arbitrary depending how the state variables are numbered.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last time, we calculated the change in our steady state concentrations when our influent concentrations changed from $c_{01}=10 \\rightarrow 20$ and $c_{03}=20 \\rightarrow 10$, corresponding with concentration loads changing from $b_1 = Q_{01}c_{01}= 50 \\rightarrow 100$ ($Q_{01}=5$ is unchanged) and $b_3 = Q_{03}c_{03}= 160 \\rightarrow 80$ ($Q_{03}=8$ is unchanged). The resulting steady state concentrations became:\n",
        "\n",
        "* $c_1 = 11.509 \\rightarrow 18.491$\n",
        "* $c_2 = 11.509 \\rightarrow 18.491$\n",
        "* $c_3 = 19.057 \\rightarrow 10.943$\n",
        "* $c_4 = 16.998 \\rightarrow 13.002$\n",
        "* $c_5 = 11.509 \\rightarrow 18.491$\n",
        "\n",
        "The inverse matrix $\\mathbf{A^{-1}}$ can actually provide insights into the relative contributions of these loadings to the changes in steady state concentration. In $\\mathbf{A^{-1}}$, each entry $a^{-1}_{ij}$ tells us how much the $i^{th}$ state variable (i.e., $c_i$) changes per 1-unit change in the $j^{th}$ loading input (i.e., $b_j$).\n",
        "\n",
        "Let's focus on $c_4$:\n",
        ">The change in $b_1$ is $\\Delta b_1=50$. To see the effect this would have, on $c_4$, we look to $a^{-1}_{4,1} = 0.06$. Based on this value, we would expect $\\Delta c_{4,1} = a^{-1}_{4,1}(\\Delta b_1)=+3$.\n",
        "\n",
        ">Additionally the change in $b_3$ is $\\Delta b_1=-80$. To see the effect this would have, on $c_4$, we look to $a^{-1}_{4,3} = 0.087$. Based on this value, we would expect $\\Delta c_{4,3} = a^{-1}_{4,3}(\\Delta b_3)=-6.96$.\n",
        "\n",
        ">When we combine these changes, we get: $\\Delta c_4 = \\Delta c_{4,1} + \\Delta c_{4,3} = -3.96$, which corresponds with the new steady state concentration we see after the change in influent concentrations: $\\Delta c_4 = c_1^{final} - c_1^{initial} = 13.002 - 16.998=-3.996$ (where differences arise because of rounding)."
      ],
      "metadata": {
        "id": "XocUh6W-dxuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This relationship gives us the general formula for how changes in load impact the steady state values of state variables:\n",
        "\n",
        "$$\\Delta x_{ij}=a^{-1}_{ij} \\Delta b_j$$\n",
        "\n",
        "The above formula is useful for determining the relative contribution of different changes in loadings to the total changes observed in the state variable."
      ],
      "metadata": {
        "id": "uNK9vAuUoC2-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvoOslBKwS96"
      },
      "source": [
        "### Condition Number"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The condition number of a matrix $\\mathbf{A}$ is:\n",
        "\n",
        "$$\\kappa(\\mathbf{A})=||\\mathbf{A}|| \\cdot ||\\mathbf{A^{-1}}||$$\n",
        "\n",
        "Where $||\\mathbf{A}||$ indicates the norm of $\\mathbf{A}$, which is a non-negative scalar that represents the magnitude and size of $\\mathbf{A}$. There are various ways to take the matrix norm (e.g., 2-Norm, column-sum, Frobenius), which would impact how $\\kappa(\\mathbf{A})$ is calculated.\n",
        "\n",
        "The condition number provides information about how much we can trust our solution based on the stability of our system, how error becomes amplified, numerical reliability, and digit loss impacting precision. In general:\n",
        "\n",
        "* $\\kappa(\\mathbf{A})$ ~ $10^1$ to $10^3$: System is stable and accurate.\n",
        "* $\\kappa(\\mathbf{A})$ ~ $10^3$ to $10^6$: System is sensitive to errors.\n",
        "* $\\kappa(\\mathbf{A})$ > $10^8$: System is ill-conditioned.\n",
        "* $\\kappa(\\mathbf{A})$ = $\\infty$: System is singular (not invertible)."
      ],
      "metadata": {
        "id": "lLht9JSEqk-k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pmq0x2yzwS96"
      },
      "outputs": [],
      "source": [
        "k_1 = np.linalg.cond(A, 'fro') # Use the Frobenius (Euclidean) norm\n",
        "print(k_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LY8DDlJ2wS96"
      },
      "outputs": [],
      "source": [
        "k_2 = sl.norm(A) * sl.norm(Ainv) # Should match\n",
        "print(k_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vo1fXYSwS96"
      },
      "source": [
        "Because the condition number is low. We are not concerned about a singular matrix.\n",
        "\n",
        "See below for an example of an ill-conditioned matrix. The closer the value `1.00001` gets to 1, the higher the condition number will be, and the fewer digits of precision we will be able to trust in the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiEvBdPmwS96"
      },
      "outputs": [],
      "source": [
        "r = 0.00001\n",
        "M = np.array([[10, 1], [10, 1+r]])\n",
        "M_cond = np.linalg.cond(M, 'fro')\n",
        "\n",
        "print(M_cond)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to estimate the number of suspect digits (recall that numbers in Google Colab retain ~16 digits of precision) we can calculate this by taking the the log of our condition number:\n",
        "\n",
        "$$Suspect\\ Digits = log_{10}(\\kappa(\\mathbf{A}))$$\n",
        "\n"
      ],
      "metadata": {
        "id": "VyiX2MEWvq8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sus_digits = np.log10(M_cond)\n",
        "\n",
        "print(sus_digits) # Output: ~6. Indicates we should only trust ~10 sig figs."
      ],
      "metadata": {
        "id": "pQKxCJH4xxxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "❓ Adjust `r` to see the impact on the number of suspect digits. How does decreasing `r` by an order of magnitude change the number of suspect digits?"
      ],
      "metadata": {
        "id": "NoVK3c2F8tVR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [???]"
      ],
      "metadata": {
        "id": "tIBd60uE9DJE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gauss-Seidel Method"
      ],
      "metadata": {
        "id": "N0F9InwLyLzj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Gauss-Seidel Method is an interative approach used to solve large systems of linear equations. This technique can be more efficient than LU Decomposition, especially if our matrix $\\mathbf{A}$ is sparse and diagonally-dominant."
      ],
      "metadata": {
        "id": "lTe0Sn8czGG1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agInwMvlwS96"
      },
      "source": [
        "### Determining if a Matrix is Diagonally Dominant"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A matrix is diagonally dominant if, for every row, the magnitude of the main diagonal is greater than the sum of the magnitudes of all the other entries in that row.\n",
        "\n",
        "This is important because it will tell us if the Gauss-Seidel method will converge."
      ],
      "metadata": {
        "id": "GIxTKlNMzhGN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bBhEAZmwS96"
      },
      "outputs": [],
      "source": [
        "def is_diagonally_dominant(A):\n",
        "    diag = np.diag(np.abs(A))             # Extracts the abs values of the diagonal elements.\n",
        "    rowsum = np.sum(np.abs(A), axis=1)    # Computes the sum of the abs values across each row.\n",
        "    return np.all(diag > rowsum - diag)   # Compares diagonal element to the row sum (- corresponding diagonal element).\n",
        "                                          # Will output False if any row doesn't meet this condition.\n",
        "is_diagonally_dominant(A)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, our matrix $\\mathbf{A}$ is not going to work with the Gauss-Seidel method:\n",
        "$$\n",
        "\\mathbf{A}=\n",
        "\\begin{bmatrix}\n",
        "6 & 0 & -1 & 0 & 0\\\\\n",
        "-3 & 3 & 0 & 0 & 0\\\\\n",
        "0 & -1 & 9 & 0 & 0\\\\\n",
        "0 & -1 & -8 & 11 & -2\\\\\n",
        "-3 & -1 & 0 & 0 & 4\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\\\n",
        "Let's use the another matrix from the textbook instead to illustrate how the Gauss-Seidel method works:\n",
        "$$\n",
        "\\mathbf{A}=\n",
        "\\begin{bmatrix}\n",
        "8 & 3 & -3\\\\\n",
        "-2 & -8 & 5\\\\\n",
        "3 & 5 & 10\n",
        "\\end{bmatrix}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "8GUjwLVy0wY8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aobpU0lmwS96"
      },
      "outputs": [],
      "source": [
        "# Reset variables\n",
        "%reset -f\n",
        "import numpy as np\n",
        "import scipy.linalg as sl\n",
        "\n",
        "\n",
        "# Re-define A and b\n",
        "A = np.array([[8, 3, -3], [-2, -8, 5], [3, 5, 10]])\n",
        "b = np.array([14, 5, -8]).T\n",
        "\n",
        "# Re-define is_diagonally_dominant function\n",
        "def is_diagonally_dominant(A):\n",
        "    diag = np.diag(np.abs(A))             # Extracts the abs values of the diagonal elements.\n",
        "    rowsum = np.sum(np.abs(A), axis=1)    # Computes the sum of the abs values across each row.\n",
        "    return np.all(diag > rowsum - diag)   # Compares diagonal element to the row sum (- corresponding diagonal element).\n",
        "                                          # Will output False if any row doesn't meet this condition.\n",
        "\n",
        "\n",
        "# Compute whether new A is diagonally dominant\n",
        "is_diagonally_dominant(A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxtKbZz3wS96"
      },
      "source": [
        "## Gauss-Seidel Iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that the Gauss-Seidel initializes our state variables $\\mathbf{x}$ as an array of zeros (iteration = $k$). Then, each  these values are updated by successively solving each equation with the previously values for $\\mathbf{x}$ and immediately updating these values based on the result:\n",
        "\n",
        "$$x_1^{(k+1)}=\\frac{1}{a_{11}} \\big(b_1 - a_{12}x_2^{(k)}- a_{13}x_3^{(k)} \\big)$$\n",
        "\n",
        "$$x_2^{(k+1)}=\\frac{1}{a_{22}} \\big(b_2 - a_{21}x_1^{(k+1)}- a_{23}x_3^{(k)} \\big)$$\n",
        "\n",
        "$$x_3^{(k+1)}=\\frac{1}{a_{33}} \\big(b_3 - a_{31}x_1^{(k+1)}- a_{32}x_2^{(k+1)} \\big)$$\n",
        "\n",
        "\n",
        "Note: The error is defined by the norm of $\\mathbf{A}\\mathbf{x} - \\mathbf{b}$. Loop until tolerance `1e-8`."
      ],
      "metadata": {
        "id": "yvenamfI3jdG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "💪 In the `for` loop complete the code for re assigning values for $\\mathbf{x_i}$:"
      ],
      "metadata": {
        "id": "CMjrq3Ah-5aK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cf2mtQUMwS96"
      },
      "outputs": [],
      "source": [
        "n = 3\n",
        "x = np.zeros(n)\n",
        "err = 9999\n",
        "errors = []\n",
        "num_iter = 0\n",
        "\n",
        "while err > 1e-8:\n",
        "    for i in range(n): # loop over variables\n",
        "        x[i]  = # [Fill in code here.]\n",
        "\n",
        "    err = sl.norm(A @ x - b, 2) # The \"2\" specifies taking the Euclidean vector norm\n",
        "    errors.append(err) # Store these for plotting\n",
        "    num_iter += 1\n",
        "\n",
        "# Print Result\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-pGp-eowS96"
      },
      "outputs": [],
      "source": [
        "# Plot Convergence\n",
        "import matplotlib.pyplot as plt\n",
        "plt.semilogy(errors) # Plots a semi-log plot, where the y-axis is in log scale.\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Log Error (norm)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqpkmha1wS96"
      },
      "source": [
        "Each iteration, $n$ variables are updated with a total of $n$ arithmetic operations each. If $k$ iterations are performed, the total operation count scales as $O(kn^2)$. Compared to Gauss elimination $O(n^3)$, this iterative method may be helpful in larger systems of equations where $k < n$. However, that is not the case here, where $n=3$ and $k=26$ iterations are needed to reach a tolerance of `1e-8`."
      ]
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": "40",
        "lenType": 16,
        "lenVar": "100"
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}